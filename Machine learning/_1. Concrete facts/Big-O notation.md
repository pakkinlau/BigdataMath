- 17-10-2022: created

- Big O notation is a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. 
- In computer science, big O notation is used to classify algorithms according to how their run time or space requirements grow as the input size grows.
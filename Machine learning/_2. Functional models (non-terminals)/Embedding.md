---
category:[]
alias:[embeddings]
tags:[]
---

- 23-10-2022 16:15: created

---

- Subset:
	- Graphs
		- [[node embedding]]
	- NLP tasks
		- [[Word representation]]
		- modular use of text representation
		- [[shallow embedding]]
			- [[Matrix factorization]]
			- [[Random walk]]
		- deep embedding
			- [[autoencoder]]
			- neighborhood aggregation methods
	- Image
		- Image embeddings
	- Recommendation systems
		- [[User/item embeddings]]
	- Tabular data:
		- Entity embedding

---


- Motivation:
	- Instead of comparing manually-combined [[feature]] [[Data|data]], you can reduce the feature data to [[representation]] called embeddings. (R2) Related: [[dimensionality reduction]]
- Definition:
	- "embedding" refers to the process of representing words, phrases, sentences, or documents as dense, continuous vectors in a high-dimensional space. 
	- These vector representations are designed to capture the semantic and contextual meaning of the text, allowing machine learning models to work effectively with textual data.
	- Traditional embedding:
		- Traditional NLP techniques often represented words as one-hot vectors, where each word is represented as a sparse binary vector with a single "1" and all other elements as "0." This representation is highly inefficient and lacks any inherent semantic information.
- Variations:
	- [[Sparse]]
	- [[dense]]

- Characteristics:
	- Embeddings are often used to represent high-dimensional data, such as words or documents, in a lower-dimensional space 
	- Why?
		- Dimensionality reduction:
			- High-dimensional data, such as natural language text or image features, can be computationally expensive to work with. By reducing the [[dimensionality]], you can significantly speed up processing and reduce memory requirements. 
		- Semantic meaning:
			- Embeddings aim to capture the semantic meaning or relationships between data points. In the case of natural language, words with similar meanings should have similar embeddings. In a lower-dimensional space, these semantic relationships can be more easily visualized and understood.
		- Generalization:
			- Embeddings help in generalizing from limited data. When you represent words or concepts in a lower-dimensional space, you can find similarities between entities that might not have appeared together frequently in the training data. This is crucial for tasks like natural language understanding and recommendation systems.
			- Need more explanations !
		- Feature learning:
			- Embedding models, such as Word2Vec, GloVe, or neural network-based embeddings, learn to encode features automatically from the data. This is beneficial because it reduces the need for manual feature engineering, allowing the model to adapt to the specific characteristics of the data.
		- Improved performance
			- Many machine learning algorithms work better in lower-dimensional spaces. Embeddings can enhance the performance of downstream tasks, such as text classification, sentiment analysis, machine translation, and information retrieval.
		- Efficient storage:
			- Embeddings are more memory-efficient than one-hot encoding or bag-of-words representations, which can become impractical for large vocabularies. Storing and manipulating dense vectors in a lower-dimensional space is more manageable.
		- Transferability:
			- Pre-trained embeddings, such as Word2Vec or pre-trained language model embeddings like BERT and GPT, can be transferred and fine-tuned for specific tasks. This transfer learning approach leverages knowledge learned from vast amounts of data, even if your dataset is relatively small.
		- Visualization:
			- Lower-dimensional embeddings allow for easy visualization, making it possible to explore and analyze the relationships between data points visually. This can be particularly valuable for data exploration and model interpretation.

- Connections to mathematics:
	- [[Spanning set]]


- What is embeddings in [[machine learning]]?
	- Embeddings are generated by training a supervised [[Deep|deep neural network]] on the [[feature]] [[Data|data]] itself.
	- Embeddings are the by-products from neurons of the neural nets completing tasks of putting data inputs to some predictions.
	- Good pre-trained embeddings should be independent of [[downstream tasks|downstream task]]. Such as [[GloVe]].
	- The embeddings map the feature data to a vector in an [[embedding space]].
	- It is kind of [[representation]] that is a relatively low-[[dimensionality|dimensional]] space into which you can translate high-dimensional vectors. (R1)
	- Embeddings make it easier to do machine learning on large inputs like [[sparse]] vectors representing words. (R1)
	- Ideally, an embedding captures some of the [[semantics]] of the input by placing semantically [[similarity|similar]] inputs close together in the [[embedding space]]. An embedding can be learned and reused across models.

![[Pasted image 20221023165746.png]]
- Fig: Manual similarity versus [[supervised learning|supervised]] similarity measure. (R2)

- How to make it?
	- No separate training process needed, the embedding layer is just a hidden layer with one unit per dimension. 
	- Supervised information (eg: users watched the same two movies) tailors the learned embeddings for the desired task
	- Intuitively the hidden units discover how to organize the items in the d-dimensional space in a way to best optimize the final objective. 

---
- My thought:
	- Embedding can be think as "a plain sheet of paper" that providing a space for the model to write down its learning result down to paper. 

### Nuances of embeddings
1. Continuous Vector Representation: 
	- Embeddings do provide a way to represent observations (e.g., words, images, categorical data) in a continuous vector space. Each element in the vector holds a numerical value, and the relative positions of the vectors encode the relationships between the observations. However, the vectors are not written down manually; they are learned by machine learning algorithms from the data. The process of learning embeddings involves training a model to find the optimal representations that capture meaningful patterns and relationships in the data.
    
2. Dimensionality and Structure: 
	- The dimensionality of an embedding refers to the length of the vectors that represent the observations. Different types of embeddings can have varying dimensionalities. For example, word embeddings might have hundreds of dimensions, whereas image embeddings could have thousands. 
	- The structure of embeddings is not arbitrary; it is derived from the patterns and relationships present in the data. Changing the dimensionality of the embedding space can affect the quality of the representations and may require retraining the model to learn new embeddings.
    
3. Interpretation and Generalization: 
	- While embeddings are learned and utilized by the model for internal computations, they are not merely for the model's own interpretation. 
	- The primary purpose of embeddings is to provide a dense, meaningful representation that facilitates generalization and information extraction from the data. These representations are used to enhance various machine learning tasks like classification, clustering, and recommendation.
    
4. Transfer Learning: 
	- In practice, embeddings can also be pre-trained on large datasets and then fine-tuned on specific tasks, leveraging transfer learning. For example, word embeddings pre-trained on a massive corpus can be fine-tuned on a smaller dataset for a specific NLP task, allowing the model to benefit from the knowledge captured in the initial embedding space.




---
## Reference

1. [[(Course) google developers - machine learning courses]]
2. (Course) google developers - foundational courses
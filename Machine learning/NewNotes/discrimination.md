---
category:[]
alias:[discriminating]
tags:[]
---

- 24-10-2022 00:08: created

- subset:
	- [[Discriminative learning algorithms]]

- What is discriminating in [[machine learning]]?
	- 

- Discriminatory Bias in Training Data
	- Discrimination impacts social goods when classification and decision making is based on inaccurate information (for example, thinking that everyone over 7ft is a bad babysitter). These ideas are often perpetuated by human biases, and become embedded in data that is used to train algorithms. (R1)
	- In this case, the biases of humans are not mitigated by the machine learning algorithm. In fact, they are reproduced in the classifications that are made. (R1)
	- This bias is also present in natural language processing, which focuses on textual data. A good example of this is the research paper titled “Man is to Computer Programmer as Women is to Homemaker? Debiasing Word Embeddings”, which showed automatically generated analogies from the software’s vectors, such as man → computer-programmer, and women → homemaker. These reflect sexism in the original texts. (R1)

---
## Reference

1. Matthew Stewart's blog: https://towardsdatascience.com/machine-learning-and-discrimination-2ed1a8b01038#:~:text=Discrimination%20impacts%20social%20goods%20when,is%20used%20to%20train%20algorithms.
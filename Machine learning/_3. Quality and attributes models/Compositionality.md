- 26-9-2022: created

- It is based on the idea that "one model can't do it all."
	- machine learning development can no longer rely on a steady growth in computational power to develop even more powerful and effective models. 
- By combining several of neural networks to perform segments of the complete task, the model as a whole performs much better at these intricate tasks while maintaining reasoable computing space. 
	- Eg: chatbot has 3 actions: chitchat, information retrieval and action. We can opt for a more distributed system. "pleasantries network", "info retrieval network", "action network".
	- eg: The "product recommendation service" is composed by: Product repair assessment CV model + chatbot ordering app model


- Little consensus exists on whether neural networks are able to generalize compositionally.  <-- Low informative sentence

- (to foster successful generalization to novel settings and environments)

---

- Compositionality in language (linguistic and philosophical theory)


---
## Reference:
- [[(Paper) On the Opportunities and Risks of Foundation Models (Bommasani et. al, 2021)]]
- Paper 
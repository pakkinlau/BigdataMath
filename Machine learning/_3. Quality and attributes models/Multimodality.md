- 26-9-2022: created

- Definition
	- It referes to the combination of multiple sensory and communicative literacies or modes, such as sight, sound, print, image, video, music.... that contribute to an audience's understanding of a composition

- Multimodality in language learning: 
	- Tasks such as understanding a televised weather forecast (medium) involves understanding spojen language, written language, weather specific language (such as temerature scales)

- In machine learning
	- Multimodal [[Deep ]]
		- Source: https://towardsdatascience.com/multimodal-deep-learning-ce7d1d994f4
		- 1. The most common method in practice is to combine high-level embeddings from the different inputs by concatenating them and then applying a softmax. 
			- The problem with this approach is that it would give an equal importance to all the sub-networks / modalities which is highly unlikely in real-life situations.
		- 2. Weighted combination of networks
			- Loss function after theta weight is given to each sub-network.

![[Pasted image 20220927003226.png]]
![[Pasted image 20220927002931.png]]
![[Pasted image 20220927003153.png]]



- Figure: 


- NN architecture that is multimodal:
	- Visual question answering (Visual question answering. , Antol et. al, 2015)
	- Visual commonsense reasoning ( From recognition to cognition: Visual commonsense reasoning, Zerllers et. al, 2019)
	- Visual dialogue
	- Phrase grounding
	- Audio signal processing 

- 

---
## Reference

- [[(Paper) On the Opportunities and Risks of Foundation Models (Bommasani et. al, 2021)]]
- Paper --  What is multimodality
- Wikipedia